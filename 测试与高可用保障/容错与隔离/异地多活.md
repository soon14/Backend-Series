# 异地多活

机房之间的延时：微博北京的两个核心机房间延时在 1ms 左右，但北京机房到广州机房则有近 40ms 的延时。对比一下，微博核心 Feed 接口的总平均耗时也就在 120ms 左右。微博 Feed 会依赖几十个服务上百个资源，如果都跨机房请求，性能将会惨不忍睹；专线问题：为了做广州机房外部，微博租了两条北京到广州的专线，成本巨大。同时单条专线的稳定性也很难保障，基本上每个月都会有或大或小的问题；数据同步问题：MySQL 如何做数据同步？HBase 如何做数据同步？还有各种自研的组件，这些统统要做多机房数据同步。几十毫秒的延时，加上路途遥远导致的较弱网络质量(我们的专线每个月都会有或大或小的问题)，数据同步是非常大的挑战；依赖服务部署问题：如同阿里目前只做了交易单元的 “ 异地双活 ”，微博部署时也面临核心服务过多依赖小服务的问题。将小服务全部部署改造成本、维护成本过大，不部署则会遇到之前提到的机房之间延时导致整体性能无法接受的问题；配套体系问题：只是服务部署没有流量引入就不能称为 “ 双活 ”，而要引入流量就要求配套的服务和流程都能支持异地部署，包括预览、发布、测试、监控、降级等都要进行相应改造；

整个业界传统的做法，异地是用来做一个冷备份的，等这边另外一个城市全部挂掉了，才会切过去。我们当时也是按照这个方式去尝试的，尝试了一年左右，我们觉 得冷备的方向对我们来讲有两个问题：第一个问题是成本太高。我们需要备份全站，而整个阿里巴巴网站，包括淘宝、天猫、聚划算等等，所有加起来，是一个非常 大的量，备份成本非常高。第二个问题是，冷备并不是一直在跑流量的，所以有个问题，一旦真的出问题了，未必敢切过去。因为不知道切过去到底能不能起来，而 且整个冷备恢复起来要花多长时间，也不敢保证。因此在尝试之后，我们发现这个方向对我们而言并不好。最关键的原因是，我们在 2013 年左右碰到了几个问题。首先，阿里巴巴的机房不仅仅给电商用，我们有电商，有物流，有云，有大数据，所有业务共用机 房。随着各种业务规模的不断增长，单个城市可能很难容纳下我们，所以我们面临的问题是，一定需要去不同的城市建设我们的数据中心。其次是我们的伸缩规模的 问题。整个淘宝的量，交易量不断攀升，每年的双十一大家都看到了，增长非常快。而我们的架构更多还是在 2009 年以前确定的一套架构，要不断的加机器，这 套架构会面临风险。如果能够做到异地部署，就可以把伸缩规模缩小。虽然原来就是一套巨大的分布式应用，但是其实可以认为是一个集群，然后不断的加机器。但是在这种情况下，随着不断加机器，最终在整个分布式体系中，一定会有一个点是会出现风险的，会再次到达瓶颈，那时就无法解决了。

异地部署，从整个业界的做法上来讲，主要有几家公司，比如 Google、Facebook ，这两家是比较典型的，Google 做到了全球多个数据中 心，都是多活的。但是 Google 具体怎么做的，也没有多少人了解。另外一家就是 Facebook，我们相对更了解一些，Facebook 在做多个数据中 心时，比如说美国和欧洲两个数据中心，确实都在支撑流量。但是欧洲的用户有可能需要访问美国的数据中心，当出现这种状况时，整个用户体验不是很好。国内的情况，我们知道的像银行，还有其他一些行业，倾向于做异地灾备。银行一般都会有两地，一个地方是热点，另一个地方是冷备。当遇到故障时，就没 有办法做出决定，到底要不要切到灾备数据中心，他们会碰到我们以前摸索时所面对的问题，就是不确定切换过程到底要多久，灾备中心到底多久才能把流量接管起 来。而且接管以后，整个功能是不是都正常，也可能无法确定。刚才也提到过，冷备的话，我们要备份全站，成本是非常高的。如果每个地点都是活的，这些数据中心就可以实时承担流量，任何一点出问题，都可以直接切掉，由另外一点直接接管。相对冷备而言，这是一套可以运行的模式，而且风险非常低。
